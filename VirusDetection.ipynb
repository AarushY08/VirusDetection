{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3hhICej54lH+4h0kn6YgT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":996},"id":"FCl9XSPogPbV","executionInfo":{"status":"ok","timestamp":1734067132563,"user_tz":360,"elapsed":50774,"user":{"displayName":"Aarush","userId":"18404890759779363953"}},"outputId":"b999343c-1863-48a8-c06b-bade9e55f0a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 99.75%\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      benign       0.99      1.00      1.00     14969\n","     malware       1.00      0.99      1.00     15031\n","\n","    accuracy                           1.00     30000\n","   macro avg       1.00      1.00      1.00     30000\n","weighted avg       1.00      1.00      1.00     30000\n","\n","\n","Feature Importances:\n","nvcsw          0.412002\n","maj_flt        0.207704\n","prio           0.206994\n","nivcsw         0.131989\n","min_flt        0.024867\n","millisecond    0.016444\n","dtype: float64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-1-cb0444c6ae49>:41: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.barplot(x=feature_importance.values, y=feature_importance.index, palette=\"coolwarm\")\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Cross-Validation Accuracy: 78.44%\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Load and preprocess the dataset\n","file_path = \"Malware_dataset.csv\"  # Replace with your dataset path\n","data = pd.read_csv(file_path)\n","\n","# Keep relevant columns\n","columns_to_keep = [\"millisecond\", \"classification\", \"prio\", \"nvcsw\", \"nivcsw\", \"min_flt\", \"maj_flt\"]\n","data = data[columns_to_keep].dropna()\n","\n","# Define features and target\n","X = data.drop(\"classification\", axis=1)\n","y = data[\"classification\"]\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Random Forest with reduced complexity\n","clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n","clf.fit(X_train, y_train)\n","\n","# Predictions and evaluation\n","y_pred = clf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Feature Importance\n","feature_importance = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n","print(\"\\nFeature Importances:\")\n","print(feature_importance)\n","\n","# Plot Feature Importance\n","plt.figure(figsize=(8, 5))\n","sns.barplot(x=feature_importance.values, y=feature_importance.index, palette=\"coolwarm\")\n","plt.title(\"Feature Importances\")\n","plt.xlabel(\"Importance\")\n","plt.tight_layout()\n","plt.show()\n","\n","\n","from sklearn.model_selection import cross_val_score\n","cv_scores = cross_val_score(clf, X, y, cv=5)\n","print(f\"Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%\")\n"]},{"cell_type":"markdown","source":["Start with one column and write down the accuracy and cross validation accuracy and keep adding one new column and repeat\n","\n","See which one had the highest accuracy and highest cross validation accuracy so it doesnt overfit"],"metadata":{"id":"ssM4i1vEleqz"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset\n","file_path = \"Malware_dataset.csv\"\n","data = pd.read_csv(file_path)\n","\n","# Drop unnecessary columns\n","columns_to_keep = [\n","    \"nvcsw\", \"maj_flt\", \"prio\", \"nivcsw\", \"min_flt\", \"millisecond\", \"classification\"\n","]\n","data = data[columns_to_keep]\n","\n","# Handle missing values\n","data = data.dropna()\n","\n","# Encode the target variable\n","le = LabelEncoder()\n","data[\"classification\"] = le.fit_transform(data[\"classification\"])\n","\n","# Define features (X) and target (y)\n","X = data.drop(\"classification\", axis=1)\n","y = data[\"classification\"]\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Initialize k-fold cross-validation\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","kfold_accuracies = []\n","\n","for train_index, test_index in kf.split(X_scaled):\n","    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    y_train_categorical = to_categorical(y_train)\n","    y_test_categorical = to_categorical(y_test)\n","\n","    # Build the TensorFlow model\n","    model = Sequential([\n","        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","        Dropout(0.3),\n","        Dense(32, activation='relu'),\n","        Dropout(0.2),\n","        Dense(y_train_categorical.shape[1], activation='softmax')\n","    ])\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    # Train the model\n","    model.fit(\n","        X_train, y_train_categorical,\n","        validation_split=0.2,\n","        epochs=10,\n","        batch_size=64,\n","        verbose=1\n","    )\n","\n","    # Evaluate the model\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n","    kfold_accuracies.append(test_accuracy)\n","\n","# Calculate the average accuracy across folds\n","average_cv_accuracy = np.mean(kfold_accuracies)\n","print(f\"Cross-Validation Accuracy: {average_cv_accuracy * 100:.2f}%\")\n","\n","# Final training on all data for test accuracy\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","model.fit(\n","    X_train, y_train_categorical,\n","    validation_split=0.2,\n","    epochs=10,\n","    batch_size=64,\n","    verbose=1\n",")\n","\n","final_loss, final_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n","print(f\"Final Test Accuracy: {final_accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulcT2QVSgrkp","executionInfo":{"status":"ok","timestamp":1734069365484,"user_tz":360,"elapsed":198725,"user":{"displayName":"Aarush","userId":"18404890759779363953"}},"outputId":"41783b80-ca69-4ed6-e427-d43825c737e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4380 - val_accuracy: 0.9029 - val_loss: 0.2705\n","Epoch 2/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8813 - loss: 0.2752 - val_accuracy: 0.9148 - val_loss: 0.2797\n","Epoch 3/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2383 - val_accuracy: 0.9112 - val_loss: 0.2686\n","Epoch 4/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2180 - val_accuracy: 0.9074 - val_loss: 0.2780\n","Epoch 5/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.1969 - val_accuracy: 0.9067 - val_loss: 0.2617\n","Epoch 6/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1776 - val_accuracy: 0.9027 - val_loss: 0.2492\n","Epoch 7/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.1641 - val_accuracy: 0.9105 - val_loss: 0.2306\n","Epoch 8/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.1537 - val_accuracy: 0.9047 - val_loss: 0.2412\n","Epoch 9/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1418 - val_accuracy: 0.9055 - val_loss: 0.2455\n","Epoch 10/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.1356 - val_accuracy: 0.9114 - val_loss: 0.2368\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.4352 - val_accuracy: 0.9203 - val_loss: 0.2692\n","Epoch 2/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2734 - val_accuracy: 0.9121 - val_loss: 0.3028\n","Epoch 3/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2415 - val_accuracy: 0.9156 - val_loss: 0.2956\n","Epoch 4/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2208 - val_accuracy: 0.9237 - val_loss: 0.2777\n","Epoch 5/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.2077 - val_accuracy: 0.9201 - val_loss: 0.2733\n","Epoch 6/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.1987 - val_accuracy: 0.9234 - val_loss: 0.2802\n","Epoch 7/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.1885 - val_accuracy: 0.9176 - val_loss: 0.2649\n","Epoch 8/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1781 - val_accuracy: 0.9236 - val_loss: 0.2713\n","Epoch 9/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.1709 - val_accuracy: 0.9312 - val_loss: 0.2525\n","Epoch 10/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1636 - val_accuracy: 0.9202 - val_loss: 0.2859\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.4249 - val_accuracy: 0.9124 - val_loss: 0.2454\n","Epoch 2/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2706 - val_accuracy: 0.9155 - val_loss: 0.2496\n","Epoch 3/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2371 - val_accuracy: 0.9241 - val_loss: 0.2437\n","Epoch 4/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2183 - val_accuracy: 0.9182 - val_loss: 0.2547\n","Epoch 5/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2067 - val_accuracy: 0.9064 - val_loss: 0.2446\n","Epoch 6/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.1941 - val_accuracy: 0.9107 - val_loss: 0.2442\n","Epoch 7/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.1830 - val_accuracy: 0.9132 - val_loss: 0.2726\n","Epoch 8/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.1731 - val_accuracy: 0.9099 - val_loss: 0.2657\n","Epoch 9/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.1665 - val_accuracy: 0.9070 - val_loss: 0.2703\n","Epoch 10/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1568 - val_accuracy: 0.9013 - val_loss: 0.2734\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4340 - val_accuracy: 0.9006 - val_loss: 0.2656\n","Epoch 2/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2755 - val_accuracy: 0.9129 - val_loss: 0.2345\n","Epoch 3/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2416 - val_accuracy: 0.9144 - val_loss: 0.2318\n","Epoch 4/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2185 - val_accuracy: 0.9332 - val_loss: 0.2064\n","Epoch 5/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2051 - val_accuracy: 0.9221 - val_loss: 0.2238\n","Epoch 6/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.1919 - val_accuracy: 0.9346 - val_loss: 0.1982\n","Epoch 7/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.1792 - val_accuracy: 0.9290 - val_loss: 0.2008\n","Epoch 8/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.1703 - val_accuracy: 0.9312 - val_loss: 0.2235\n","Epoch 9/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1574 - val_accuracy: 0.9292 - val_loss: 0.2125\n","Epoch 10/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1470 - val_accuracy: 0.9183 - val_loss: 0.2450\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.4317 - val_accuracy: 0.9001 - val_loss: 0.2709\n","Epoch 2/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2746 - val_accuracy: 0.9221 - val_loss: 0.2661\n","Epoch 3/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.2420 - val_accuracy: 0.9139 - val_loss: 0.2804\n","Epoch 4/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2180 - val_accuracy: 0.9101 - val_loss: 0.2669\n","Epoch 5/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2012 - val_accuracy: 0.9070 - val_loss: 0.2290\n","Epoch 6/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.1860 - val_accuracy: 0.9006 - val_loss: 0.2471\n","Epoch 7/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.1759 - val_accuracy: 0.9084 - val_loss: 0.2259\n","Epoch 8/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.1633 - val_accuracy: 0.9154 - val_loss: 0.2225\n","Epoch 9/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.1545 - val_accuracy: 0.9107 - val_loss: 0.2293\n","Epoch 10/10\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.1478 - val_accuracy: 0.9133 - val_loss: 0.2267\n","Cross-Validation Accuracy: 94.53%\n","Epoch 1/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1499 - val_accuracy: 0.9587 - val_loss: 0.0966\n","Epoch 2/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1340 - val_accuracy: 0.9601 - val_loss: 0.0926\n","Epoch 3/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.1319 - val_accuracy: 0.9611 - val_loss: 0.0858\n","Epoch 4/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1251 - val_accuracy: 0.9691 - val_loss: 0.0850\n","Epoch 5/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1245 - val_accuracy: 0.9743 - val_loss: 0.0778\n","Epoch 6/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1190 - val_accuracy: 0.9734 - val_loss: 0.0765\n","Epoch 7/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1164 - val_accuracy: 0.9751 - val_loss: 0.0709\n","Epoch 8/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1129 - val_accuracy: 0.9796 - val_loss: 0.0700\n","Epoch 9/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1116 - val_accuracy: 0.9811 - val_loss: 0.0647\n","Epoch 10/10\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1072 - val_accuracy: 0.9832 - val_loss: 0.0606\n","Final Test Accuracy: 98.42%\n"]}]},{"cell_type":"code","source":["#Deepseek\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, accuracy_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.regularizers import l2\n","\n","# Load the dataset\n","file_path = \"Malware_dataset.csv\"\n","data = pd.read_csv(file_path)\n","\n","# Drop unnecessary columns\n","columns_to_keep = [\n","    \"nvcsw\", \"maj_flt\", \"prio\", \"nivcsw\", \"min_flt\", \"millisecond\", \"classification\"\n","]\n","data = data[columns_to_keep]\n","\n","# Handle missing values\n","data = data.dropna()\n","\n","# Encode the target variable\n","le = LabelEncoder()\n","data[\"classification\"] = le.fit_transform(data[\"classification\"])\n","\n","# Define features (X) and target (y)\n","X = data.drop(\"classification\", axis=1)\n","y = data[\"classification\"]\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Initialize k-fold cross-validation\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","kfold_accuracies = []\n","\n","for train_index, test_index in kf.split(X_scaled):\n","    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    y_train_categorical = to_categorical(y_train)\n","    y_test_categorical = to_categorical(y_test)\n","\n","    # Build the TensorFlow model\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n","        Dropout(0.3),\n","        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","        Dropout(0.2),\n","        Dense(y_train_categorical.shape[1], activation='softmax')\n","    ])\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    # Train the model\n","    model.fit(\n","        X_train, y_train_categorical,\n","        validation_split=0.2,\n","        epochs=20,\n","        batch_size=64,\n","        verbose=1\n","    )\n","\n","    # Evaluate the model\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n","    kfold_accuracies.append(test_accuracy)\n","\n","    # Print classification report\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    print(classification_report(y_test, y_pred_classes))\n","\n","# Calculate the average accuracy across folds\n","average_cv_accuracy = np.mean(kfold_accuracies)\n","print(f\"Cross-Validation Accuracy: {average_cv_accuracy * 100:.2f}%\")\n","\n","# Final training on all data for test accuracy\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","model.fit(\n","    X_train, y_train_categorical,\n","    validation_split=0.2,\n","    epochs=20,\n","    batch_size=64,\n","    verbose=1\n",")\n","\n","final_loss, final_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n","print(f\"Final Test Accuracy: {final_accuracy * 100:.2f}%\")\n","\n","# Save the model\n","#model.save(\"malware_detection_model.h5\")"],"metadata":{"id":"RhHLQOdrk6IE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739427229357,"user_tz":360,"elapsed":609294,"user":{"displayName":"Aarush","userId":"18404890759779363953"}},"outputId":"16aa9849-8830-4463-94f7-a4281090a17e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.7146 - val_accuracy: 0.9056 - val_loss: 0.2997\n","Epoch 2/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3605 - val_accuracy: 0.8913 - val_loss: 0.3520\n","Epoch 3/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.3351 - val_accuracy: 0.9149 - val_loss: 0.2873\n","Epoch 4/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3184 - val_accuracy: 0.9065 - val_loss: 0.3176\n","Epoch 5/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.3066 - val_accuracy: 0.9013 - val_loss: 0.3049\n","Epoch 6/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8950 - loss: 0.2994 - val_accuracy: 0.9183 - val_loss: 0.2875\n","Epoch 7/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2942 - val_accuracy: 0.8866 - val_loss: 0.3355\n","Epoch 8/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.2837 - val_accuracy: 0.8990 - val_loss: 0.3166\n","Epoch 9/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2770 - val_accuracy: 0.9139 - val_loss: 0.2973\n","Epoch 10/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.2761 - val_accuracy: 0.8994 - val_loss: 0.3047\n","Epoch 11/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2664 - val_accuracy: 0.8963 - val_loss: 0.3226\n","Epoch 12/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.2668 - val_accuracy: 0.9109 - val_loss: 0.2995\n","Epoch 13/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2623 - val_accuracy: 0.9092 - val_loss: 0.2986\n","Epoch 14/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2570 - val_accuracy: 0.9130 - val_loss: 0.2514\n","Epoch 15/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.2545 - val_accuracy: 0.9137 - val_loss: 0.2891\n","Epoch 16/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2502 - val_accuracy: 0.9182 - val_loss: 0.2477\n","Epoch 17/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9126 - loss: 0.2560 - val_accuracy: 0.9098 - val_loss: 0.2907\n","Epoch 18/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2494 - val_accuracy: 0.9041 - val_loss: 0.2876\n","Epoch 19/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2452 - val_accuracy: 0.9237 - val_loss: 0.2772\n","Epoch 20/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2476 - val_accuracy: 0.8954 - val_loss: 0.3365\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.99      0.92     10030\n","           1       0.99      0.84      0.91      9970\n","\n","    accuracy                           0.91     20000\n","   macro avg       0.92      0.91      0.91     20000\n","weighted avg       0.92      0.91      0.91     20000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.7168 - val_accuracy: 0.8923 - val_loss: 0.3711\n","Epoch 2/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3609 - val_accuracy: 0.9020 - val_loss: 0.3485\n","Epoch 3/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.8862 - loss: 0.3340 - val_accuracy: 0.9172 - val_loss: 0.3020\n","Epoch 4/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.3175 - val_accuracy: 0.8978 - val_loss: 0.3210\n","Epoch 5/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.3074 - val_accuracy: 0.9072 - val_loss: 0.3226\n","Epoch 6/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2969 - val_accuracy: 0.8817 - val_loss: 0.3638\n","Epoch 7/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.2902 - val_accuracy: 0.9137 - val_loss: 0.3129\n","Epoch 8/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2845 - val_accuracy: 0.8919 - val_loss: 0.3400\n","Epoch 9/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2754 - val_accuracy: 0.9013 - val_loss: 0.3051\n","Epoch 10/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2740 - val_accuracy: 0.9033 - val_loss: 0.3383\n","Epoch 11/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2685 - val_accuracy: 0.9093 - val_loss: 0.2574\n","Epoch 12/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2678 - val_accuracy: 0.9106 - val_loss: 0.2938\n","Epoch 13/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.2609 - val_accuracy: 0.9034 - val_loss: 0.3078\n","Epoch 14/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2557 - val_accuracy: 0.9087 - val_loss: 0.2712\n","Epoch 15/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2576 - val_accuracy: 0.8733 - val_loss: 0.3884\n","Epoch 16/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2520 - val_accuracy: 0.8826 - val_loss: 0.3279\n","Epoch 17/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2473 - val_accuracy: 0.9015 - val_loss: 0.3139\n","Epoch 18/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.2504 - val_accuracy: 0.9045 - val_loss: 0.2895\n","Epoch 19/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2420 - val_accuracy: 0.8841 - val_loss: 0.3296\n","Epoch 20/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2392 - val_accuracy: 0.8744 - val_loss: 0.3647\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.99      0.93      9998\n","           1       0.99      0.86      0.92     10002\n","\n","    accuracy                           0.93     20000\n","   macro avg       0.93      0.93      0.92     20000\n","weighted avg       0.93      0.93      0.92     20000\n","\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.7070 - val_accuracy: 0.9252 - val_loss: 0.3006\n","Epoch 2/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.3601 - val_accuracy: 0.9258 - val_loss: 0.2860\n","Epoch 3/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.3310 - val_accuracy: 0.9212 - val_loss: 0.2932\n","Epoch 4/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3205 - val_accuracy: 0.9046 - val_loss: 0.3459\n","Epoch 5/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.3072 - val_accuracy: 0.9127 - val_loss: 0.3214\n","Epoch 6/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.3000 - val_accuracy: 0.9297 - val_loss: 0.3128\n","Epoch 7/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.2928 - val_accuracy: 0.8921 - val_loss: 0.3794\n","Epoch 8/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9017 - loss: 0.2862 - val_accuracy: 0.8941 - val_loss: 0.3431\n","Epoch 9/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2779 - val_accuracy: 0.8851 - val_loss: 0.3258\n","Epoch 10/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2727 - val_accuracy: 0.9164 - val_loss: 0.2923\n","Epoch 11/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2694 - val_accuracy: 0.9002 - val_loss: 0.3271\n","Epoch 12/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2668 - val_accuracy: 0.8861 - val_loss: 0.3519\n","Epoch 13/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2584 - val_accuracy: 0.9135 - val_loss: 0.2632\n","Epoch 14/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2611 - val_accuracy: 0.9227 - val_loss: 0.2669\n","Epoch 15/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2549 - val_accuracy: 0.9348 - val_loss: 0.2859\n","Epoch 16/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2536 - val_accuracy: 0.8838 - val_loss: 0.3507\n","Epoch 17/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2505 - val_accuracy: 0.8983 - val_loss: 0.3199\n","Epoch 18/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2499 - val_accuracy: 0.9171 - val_loss: 0.2638\n","Epoch 19/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9196 - loss: 0.2480 - val_accuracy: 0.8987 - val_loss: 0.2981\n","Epoch 20/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2448 - val_accuracy: 0.9060 - val_loss: 0.2652\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.97      0.93      9956\n","           1       0.97      0.87      0.92     10044\n","\n","    accuracy                           0.92     20000\n","   macro avg       0.93      0.92      0.92     20000\n","weighted avg       0.93      0.92      0.92     20000\n","\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.7111 - val_accuracy: 0.9066 - val_loss: 0.3188\n","Epoch 2/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.3565 - val_accuracy: 0.8938 - val_loss: 0.3619\n","Epoch 3/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.3287 - val_accuracy: 0.9044 - val_loss: 0.3113\n","Epoch 4/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.3145 - val_accuracy: 0.9269 - val_loss: 0.2728\n","Epoch 5/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.3077 - val_accuracy: 0.9024 - val_loss: 0.3054\n","Epoch 6/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8990 - loss: 0.2959 - val_accuracy: 0.8909 - val_loss: 0.2969\n","Epoch 7/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2865 - val_accuracy: 0.9114 - val_loss: 0.3102\n","Epoch 8/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2842 - val_accuracy: 0.8865 - val_loss: 0.3578\n","Epoch 9/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2752 - val_accuracy: 0.9138 - val_loss: 0.2829\n","Epoch 10/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2708 - val_accuracy: 0.9024 - val_loss: 0.3209\n","Epoch 11/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2661 - val_accuracy: 0.9021 - val_loss: 0.3155\n","Epoch 12/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2603 - val_accuracy: 0.8876 - val_loss: 0.3610\n","Epoch 13/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2581 - val_accuracy: 0.8970 - val_loss: 0.3130\n","Epoch 14/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2534 - val_accuracy: 0.9026 - val_loss: 0.2801\n","Epoch 15/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2522 - val_accuracy: 0.9222 - val_loss: 0.2447\n","Epoch 16/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2528 - val_accuracy: 0.9060 - val_loss: 0.2723\n","Epoch 17/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2453 - val_accuracy: 0.9076 - val_loss: 0.2530\n","Epoch 18/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.2447 - val_accuracy: 0.9094 - val_loss: 0.2670\n","Epoch 19/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2398 - val_accuracy: 0.9194 - val_loss: 0.2554\n","Epoch 20/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.2401 - val_accuracy: 0.9323 - val_loss: 0.2427\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.94      0.93     10046\n","           1       0.94      0.92      0.93      9954\n","\n","    accuracy                           0.93     20000\n","   macro avg       0.93      0.93      0.93     20000\n","weighted avg       0.93      0.93      0.93     20000\n","\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.6963 - val_accuracy: 0.9155 - val_loss: 0.3283\n","Epoch 2/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3628 - val_accuracy: 0.9234 - val_loss: 0.3086\n","Epoch 3/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.3337 - val_accuracy: 0.9377 - val_loss: 0.3079\n","Epoch 4/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3199 - val_accuracy: 0.9261 - val_loss: 0.3194\n","Epoch 5/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.3128 - val_accuracy: 0.8924 - val_loss: 0.3721\n","Epoch 6/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2981 - val_accuracy: 0.9235 - val_loss: 0.2709\n","Epoch 7/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.2936 - val_accuracy: 0.9112 - val_loss: 0.3444\n","Epoch 8/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2867 - val_accuracy: 0.8858 - val_loss: 0.3549\n","Epoch 9/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2819 - val_accuracy: 0.8990 - val_loss: 0.3145\n","Epoch 10/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.2737 - val_accuracy: 0.8922 - val_loss: 0.3216\n","Epoch 11/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2678 - val_accuracy: 0.8986 - val_loss: 0.3097\n","Epoch 12/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2634 - val_accuracy: 0.9244 - val_loss: 0.2529\n","Epoch 13/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2624 - val_accuracy: 0.8890 - val_loss: 0.3615\n","Epoch 14/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2524 - val_accuracy: 0.9056 - val_loss: 0.2604\n","Epoch 15/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.2521 - val_accuracy: 0.8913 - val_loss: 0.3474\n","Epoch 16/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2530 - val_accuracy: 0.8993 - val_loss: 0.3142\n","Epoch 17/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2462 - val_accuracy: 0.9220 - val_loss: 0.2631\n","Epoch 18/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2455 - val_accuracy: 0.8920 - val_loss: 0.3142\n","Epoch 19/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2453 - val_accuracy: 0.9089 - val_loss: 0.3136\n","Epoch 20/20\n","\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2414 - val_accuracy: 0.9037 - val_loss: 0.2418\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.96      0.93      9970\n","           1       0.96      0.89      0.93     10030\n","\n","    accuracy                           0.93     20000\n","   macro avg       0.93      0.93      0.93     20000\n","weighted avg       0.93      0.93      0.93     20000\n","\n","Cross-Validation Accuracy: 92.43%\n","Epoch 1/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.2402 - val_accuracy: 0.9313 - val_loss: 0.2080\n","Epoch 2/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2332 - val_accuracy: 0.9368 - val_loss: 0.2008\n","Epoch 3/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.2334 - val_accuracy: 0.9324 - val_loss: 0.2141\n","Epoch 4/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.2322 - val_accuracy: 0.9452 - val_loss: 0.2098\n","Epoch 5/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.2294 - val_accuracy: 0.9474 - val_loss: 0.1985\n","Epoch 6/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.2289 - val_accuracy: 0.9477 - val_loss: 0.1952\n","Epoch 7/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2263 - val_accuracy: 0.9305 - val_loss: 0.2024\n","Epoch 8/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2242 - val_accuracy: 0.9427 - val_loss: 0.1873\n","Epoch 9/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.2229 - val_accuracy: 0.9429 - val_loss: 0.1982\n","Epoch 10/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.2208 - val_accuracy: 0.9181 - val_loss: 0.2127\n","Epoch 11/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.2225 - val_accuracy: 0.9424 - val_loss: 0.1893\n","Epoch 12/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.2173 - val_accuracy: 0.9444 - val_loss: 0.1907\n","Epoch 13/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2191 - val_accuracy: 0.9603 - val_loss: 0.1837\n","Epoch 14/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.2198 - val_accuracy: 0.9405 - val_loss: 0.1980\n","Epoch 15/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.2195 - val_accuracy: 0.9434 - val_loss: 0.1903\n","Epoch 16/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.2179 - val_accuracy: 0.9582 - val_loss: 0.1840\n","Epoch 17/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.2173 - val_accuracy: 0.9571 - val_loss: 0.1906\n","Epoch 18/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.2186 - val_accuracy: 0.9494 - val_loss: 0.1840\n","Epoch 19/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.2148 - val_accuracy: 0.9494 - val_loss: 0.1859\n","Epoch 20/20\n","\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.2191 - val_accuracy: 0.9457 - val_loss: 0.1924\n","Final Test Accuracy: 94.42%\n"]}]}]}